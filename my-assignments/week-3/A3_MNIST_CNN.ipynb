{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Convolutional Neural Network in Tensorflow\n",
    "\n",
    "Author: Juvid Aryaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "sys.path.append(\"..\")\n",
    "import utls\n",
    "utls.reset_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST is a dataset of 28$\\times$28 handwritten digits. The dataset comes shipped with tensorflow, so let's load it up and have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand the final dimension to a single channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train,axis=3)\n",
    "x_test = np.expand_dims(x_test,axis=3)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juvid/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:1238: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = np.random.choice(np.arange(n_train))\n",
    "\n",
    "image = x_train[example,:,:,0]\n",
    "label = y_train[example]\n",
    "\n",
    "plt.imshow(image, cmap = cm.binary)\n",
    "print(\"Digit: {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we encode the data labels as one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels):\n",
    "    \"\"\"\n",
    "    Encodes a list of labels ranging between (0-9) as one-hot vectors.\n",
    "    0 -> [1,0,0,0,0,0,0,0,0,0]\n",
    "    9 -> [0,0,0,0,0,0,0,0,0,1]\n",
    "    \"\"\"\n",
    "    one_hot_labels = []\n",
    "    for num in labels:\n",
    "        one_hot = [0.0]*10\n",
    "        one_hot[num] = 1.0\n",
    "        one_hot_labels.append(one_hot)\n",
    "    return np.array(one_hot_labels).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_oh = one_hot(y_train)\n",
    "y_test_oh = one_hot(y_test)\n",
    "y_train_oh.shape, y_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0],y_train_oh[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a small sample dataset for preliminary debugging/architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 28, 28, 1), (20, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample = x_train[0:20,:,:,:]\n",
    "y_sample_oh = y_train_oh[0:20]\n",
    "x_sample.shape, y_sample_oh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_MNIST:\n",
    "    \"\"\"\n",
    "    Define a convolutional neural network for the MNIST dataset\n",
    "    \n",
    "    Params\n",
    "    ------------\n",
    "    wd_factor : A double, the L2 regularisation factor for model parameters\n",
    "    learning_rate : A double, the learning rate for the Adam optimiser    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, wd_factor, learning_rate):\n",
    "        self.wd_factor = wd_factor # weight decay factor (L2 regulariser)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_pointer = 0 # for mini-batch housekeeping\n",
    "        self.test_pointer = 0\n",
    "        \n",
    "        self.input = tf.placeholder(dtype=tf.float32, shape=[None,28,28,1],name=\"input\")\n",
    "        self.ground_truth = tf.placeholder(dtype=tf.float32, shape=[None,10],name=\"ground_truth\")\n",
    "        print(self.input)\n",
    "        \n",
    "        # For batch norm and dropout, which work differently depending on whether you're \n",
    "        # training or testing\n",
    "        \n",
    "        self.is_training = tf.placeholder(tf.bool, name=\"is_training\")\n",
    "        \n",
    "        self._build_graph()\n",
    "        \n",
    "    def _build_graph(self):\n",
    "        \"\"\"\n",
    "        Create the convolutional neural network using the Adam optimiser and cross entropy loss\n",
    "        \"\"\"\n",
    "        weights = [] # for weight decay\n",
    "        \n",
    "        with tf.variable_scope(\"layers\"):\n",
    "            h = tf.layers.conv2d(self.input, 32, (3,3), strides=(1,1), padding=\"same\",\n",
    "                                 data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(),name='conv1')\n",
    "            print(h)\n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            print(h)\n",
    "            h = tf.nn.relu(h) # activation                        \n",
    "            \n",
    "            h = tf.layers.conv2d(h, 64, (3,3), strides=(1,1), padding=\"same\",\n",
    "                                 data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(),name='conv2') \n",
    "            print(h)\n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            print(h)\n",
    "            h = tf.nn.relu(h) # activation            \n",
    "            h = tf.layers.max_pooling2d(h, (3,3), (3,3), padding='valid') # Downsample           \n",
    "            \n",
    "            h = tf.layers.conv2d(h, 64, (3,3), strides=(1,1), padding=\"same\",\n",
    "                                 data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(),name='conv3')\n",
    "            print(h)\n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            print(h)\n",
    "            h = tf.nn.relu(h) # activation            \n",
    "            h = tf.layers.max_pooling2d(h, (3,3), (3,3), padding='valid') # Downsample           \n",
    "            h = tf.layers.flatten(h) # flatten before dense layers\n",
    "            \n",
    "            \n",
    "            # Fully connected layers\n",
    "            h = tf.layers.dense(h, 32, kernel_initializer=tf.glorot_uniform_initializer(),\n",
    "                               activation=tf.nn.relu, name='dense1')      \n",
    "            print(h)\n",
    "            h = tf.layers.dropout(h, rate=0.25, training=self.is_training, name=\"dropout1\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            self.logits = tf.layers.dense(h, 10, kernel_initializer=tf.glorot_uniform_initializer(),\n",
    "                               activation=tf.identity, name='dense2') # linear output for the loss function            \n",
    "            print(self.logits)\n",
    "            self.prediction = tf.nn.softmax(self.logits, name=\"softmax_prediction\")\n",
    "        \n",
    "        with tf.name_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits,\n",
    "                                                                                 labels=self.ground_truth))\n",
    "            self.loss += self.weight_decay() # penalise weights with L2 norm\n",
    "        \n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        \n",
    "        # When using batch-norm need to do this\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self.train_op = self.optimizer.minimize(self.loss)\n",
    "        \n",
    "    def weight_decay(self):\n",
    "        \"\"\"\n",
    "        Append the L2 penalty onto the loss function\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        for v in tf.global_variables():\n",
    "            if 'Adam' in v.name:\n",
    "                continue # do not punish optimizer variables\n",
    "            elif 'kernel' in v.name:\n",
    "                loss += self.wd_factor * tf.nn.l2_loss(v)\n",
    "        print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def train_minibatch(self, samples, labels, batch_size):\n",
    "        \"\"\"\n",
    "        Take a mini-batch from the training dataset\n",
    "        \"\"\"\n",
    "        if self.train_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.train_pointer: self.train_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.train_pointer: self.train_pointer + batch_size]\n",
    "            self.train_pointer += batch_size\n",
    "        else:\n",
    "            samples_minibatch = samples[self.train_pointer:]\n",
    "            labels_minibatch = labels[self.train_pointer:]\n",
    "            self.train_pointer += 0 # reset\n",
    "        return samples_minibatch, labels_minibatch\n",
    "    \n",
    "    def train(self, train_samples, train_labels, train_batch_size, iteration_steps, import_from_previous=False):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \n",
    "        Params\n",
    "        ----------\n",
    "        \n",
    "        train_samples: A numpy matrix containing the training data\n",
    "        train_labels: A numpy vector containing the labels corresponding to train_samples\n",
    "        train_batch_size: An int. The number of data points per mini-batch\n",
    "        iteration_steps: An int. The number of mini-batch training steps\n",
    "        import_from_previous: A bool. Load a previous model and train\n",
    "        \n",
    "        Returns\n",
    "        -----------\n",
    "        \n",
    "        losses: A numpy array, where the first column is the mini-batch index, and the \n",
    "                second column is the loss function\n",
    "        \"\"\"\n",
    "        print('Start training....')\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            if import_from_previous:\n",
    "                saver = tf.train.import_meta_graph(\"./model.meta\") # import the model\n",
    "                saver.restore(sess, './model') # populate with weights  \n",
    "            else:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                saver = tf.train.Saver() # for saving models\n",
    "            \n",
    "            for i in range(iteration_steps):\n",
    "                samples, labels = self.train_minibatch(train_samples, train_labels, train_batch_size)\n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: True}\n",
    "                _, loss = sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "                if i % 50 == 0:\n",
    "                    print(\"Minibatch loss at step {}: {}\".format(i, loss))\n",
    "                    losses.append([i, loss])\n",
    "            saver.save(sess, './model') # save the model, generating 4 files\n",
    "        return np.array(losses)\n",
    "    \n",
    "    def test_minibatch(self, samples, labels, batch_size):\n",
    "        \"\"\"\n",
    "        Take a mini-batch from the test dataset\n",
    "        \"\"\"\n",
    "        if self.test_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.test_pointer: self.test_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.test_pointer: self.test_pointer + batch_size]\n",
    "            self.test_pointer += batch_size\n",
    "            end_of_epoch = False\n",
    "        else:\n",
    "            samples_minibatch = samples[self.test_pointer:]\n",
    "            labels_minibatch = labels[self.test_pointer:]\n",
    "            self.test_pointer += 0 # reset\n",
    "            end_of_epoch = True\n",
    "        return samples_minibatch, labels_minibatch, end_of_epoch\n",
    "    \n",
    "    def test(self, test_samples, test_labels, test_batch_size):\n",
    "        \"\"\"\n",
    "        Load a model, feed it test data, and determine the loss\n",
    "        \n",
    "        Params:\n",
    "        ---------------\n",
    "        test_samples: A numpy array, containing the test data\n",
    "        test_labels: A numpy vector, containing the test labels\n",
    "        test_batch_size: An int, the number of data points per mini-batch\n",
    "        \"\"\"\n",
    "        end_of_epoch = False\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver = tf.train.import_meta_graph(\"./model.meta\") # import the model\n",
    "            saver.restore(sess, './model') # populate with weights            \n",
    "            while not end_of_epoch: # run graph\n",
    "                samples, labels, end_of_epoch = self.test_minibatch(test_samples, \n",
    "                                                                    test_labels, test_batch_size)\n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: False}                \n",
    "                losses.append(sess.run(self.loss, feed_dict=feed_dict))\n",
    "            print(\"Average test loss: {}\".format(np.mean(losses)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"layers/conv1/BiasAdd:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"layers/batch_normalization/cond/Merge:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"layers/conv2/BiasAdd:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "Tensor(\"layers/batch_normalization_1/cond/Merge:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "Tensor(\"layers/conv3/BiasAdd:0\", shape=(?, 9, 9, 64), dtype=float32)\n",
      "Tensor(\"layers/batch_normalization_2/cond/Merge:0\", shape=(?, 9, 9, 64), dtype=float32)\n",
      "Tensor(\"layers/dense1/Relu:0\", shape=(?, 32), dtype=float32)\n",
      "Tensor(\"layers/dense2/Identity:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"loss/add_4:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "WD_FACTOR = 0.0001\n",
    "LEARNING_RATE = 0.001\n",
    "tf.reset_default_graph()\n",
    "model = CNN_MNIST(WD_FACTOR, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layers/conv1/kernel:0' shape=(3, 3, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/moving_mean:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/moving_variance:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel:0' shape=(576, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/kernel/Adam:0' shape=(3, 3, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/kernel/Adam_1:0' shape=(3, 3, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel/Adam:0' shape=(3, 3, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel/Adam_1:0' shape=(3, 3, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel/Adam:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel/Adam_1:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel/Adam:0' shape=(576, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel/Adam_1:0' shape=(576, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel/Adam:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel/Adam_1:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias/Adam:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_params():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():         \n",
    "        shape = variable.get_shape()        \n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value        \n",
    "        total_parameters += variable_parameters\n",
    "    print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74858\n"
     ]
    }
   ],
   "source": [
    "count_trainable_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About a factor of 10 fewer params than the MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a learning schedule whereby we gradually reduce the learning rate with iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_schedule = [[2000,0.1],[2000,0.01],[2000,0.001],[4000,0.0001]]\n",
    "#learning_schedule = [[400,0.001]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training....\n",
      "Minibatch loss at step 0: 3.396852970123291\n",
      "Minibatch loss at step 50: 0.9064825773239136\n",
      "Minibatch loss at step 100: 0.4513855576515198\n",
      "Minibatch loss at step 150: 0.28895828127861023\n",
      "Minibatch loss at step 200: 0.2646741569042206\n",
      "Minibatch loss at step 250: 0.3018289804458618\n",
      "Minibatch loss at step 300: 0.20024149119853973\n",
      "Minibatch loss at step 350: 0.2687474191188812\n",
      "Minibatch loss at step 400: 0.23494209349155426\n",
      "Minibatch loss at step 450: 0.1456923633813858\n",
      "Minibatch loss at step 500: 0.03704576939344406\n",
      "Minibatch loss at step 550: 0.03524889796972275\n",
      "Minibatch loss at step 600: 0.02391580305993557\n",
      "Minibatch loss at step 650: 0.04079912602901459\n",
      "Minibatch loss at step 700: 0.01618035137653351\n",
      "Minibatch loss at step 750: 0.0207089614123106\n",
      "Minibatch loss at step 800: 0.014665616676211357\n",
      "Minibatch loss at step 850: 0.017326626926660538\n",
      "Minibatch loss at step 900: 0.014966344460844994\n",
      "Minibatch loss at step 950: 0.013495679944753647\n",
      "Minibatch loss at step 1000: 0.013299942947924137\n",
      "Minibatch loss at step 1050: 0.013225969858467579\n",
      "Minibatch loss at step 1100: 0.014676069840788841\n",
      "Minibatch loss at step 1150: 0.012484841048717499\n",
      "Minibatch loss at step 1200: 0.011677192524075508\n",
      "Minibatch loss at step 1250: 0.03151562809944153\n",
      "Minibatch loss at step 1300: 0.013852858915925026\n",
      "Minibatch loss at step 1350: 0.03663097694516182\n",
      "Minibatch loss at step 1400: 0.023539463058114052\n",
      "Minibatch loss at step 1450: 0.016203857958316803\n",
      "Minibatch loss at step 1500: 0.014622218906879425\n",
      "Minibatch loss at step 1550: 0.010821940377354622\n",
      "Minibatch loss at step 1600: 0.010971300303936005\n",
      "Minibatch loss at step 1650: 0.0113467862829566\n",
      "Minibatch loss at step 1700: 0.015724914148449898\n",
      "Minibatch loss at step 1750: 0.016366396099328995\n",
      "Minibatch loss at step 1800: 0.017323633655905724\n",
      "Minibatch loss at step 1850: 0.01810421422123909\n",
      "Minibatch loss at step 1900: 0.010106737725436687\n",
      "Minibatch loss at step 1950: 0.010038587264716625\n",
      "Start training....\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Minibatch loss at step 0: 0.01691802218556404\n",
      "Minibatch loss at step 50: 0.010521072894334793\n",
      "Minibatch loss at step 100: 0.027903232723474503\n",
      "Minibatch loss at step 150: 0.009906474500894547\n",
      "Minibatch loss at step 200: 0.01188540831208229\n",
      "Minibatch loss at step 250: 0.01059120986610651\n",
      "Minibatch loss at step 300: 0.026595354080200195\n",
      "Minibatch loss at step 350: 0.010758192278444767\n",
      "Minibatch loss at step 400: 0.012283616699278355\n",
      "Minibatch loss at step 450: 0.02821335569024086\n",
      "Minibatch loss at step 500: 0.038663238286972046\n",
      "Minibatch loss at step 550: 0.024973664432764053\n",
      "Minibatch loss at step 600: 0.0176791250705719\n",
      "Minibatch loss at step 650: 0.010148731991648674\n",
      "Minibatch loss at step 700: 0.02317938208580017\n",
      "Minibatch loss at step 750: 0.011145295575261116\n",
      "Minibatch loss at step 800: 0.016776321455836296\n",
      "Minibatch loss at step 850: 0.018590839579701424\n",
      "Minibatch loss at step 900: 0.010379249230027199\n",
      "Minibatch loss at step 950: 0.00973233487457037\n",
      "Minibatch loss at step 1000: 0.013001427054405212\n",
      "Minibatch loss at step 1050: 0.011708050966262817\n",
      "Minibatch loss at step 1100: 0.011117669753730297\n",
      "Minibatch loss at step 1150: 0.011002621613442898\n",
      "Minibatch loss at step 1200: 0.009325629100203514\n",
      "Minibatch loss at step 1250: 0.010732673108577728\n",
      "Minibatch loss at step 1300: 0.017832107841968536\n",
      "Minibatch loss at step 1350: 0.01911657303571701\n",
      "Minibatch loss at step 1400: 0.00912100076675415\n",
      "Minibatch loss at step 1450: 0.014946365728974342\n",
      "Minibatch loss at step 1500: 0.008686516433954239\n",
      "Minibatch loss at step 1550: 0.010854173451662064\n",
      "Minibatch loss at step 1600: 0.008047088049352169\n",
      "Minibatch loss at step 1650: 0.012361215427517891\n",
      "Minibatch loss at step 1700: 0.009992805309593678\n",
      "Minibatch loss at step 1750: 0.009139538742601871\n",
      "Minibatch loss at step 1800: 0.012972579337656498\n",
      "Minibatch loss at step 1850: 0.009012117981910706\n",
      "Minibatch loss at step 1900: 0.011633449234068394\n",
      "Minibatch loss at step 1950: 0.032486140727996826\n",
      "Start training....\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Minibatch loss at step 0: 0.015597104094922543\n",
      "Minibatch loss at step 50: 0.0188169926404953\n",
      "Minibatch loss at step 100: 0.021106507629156113\n",
      "Minibatch loss at step 150: 0.011046336963772774\n",
      "Minibatch loss at step 200: 0.008339033462107182\n",
      "Minibatch loss at step 250: 0.007677756249904633\n",
      "Minibatch loss at step 300: 0.007615291979163885\n",
      "Minibatch loss at step 350: 0.014474717900156975\n",
      "Minibatch loss at step 400: 0.008020292967557907\n",
      "Minibatch loss at step 450: 0.007411113474518061\n",
      "Minibatch loss at step 500: 0.007994502782821655\n",
      "Minibatch loss at step 550: 0.007437543943524361\n",
      "Minibatch loss at step 600: 0.007562159560620785\n",
      "Minibatch loss at step 650: 0.007204902824014425\n",
      "Minibatch loss at step 700: 0.008027737028896809\n",
      "Minibatch loss at step 750: 0.007818263955414295\n",
      "Minibatch loss at step 800: 0.02595023438334465\n",
      "Minibatch loss at step 850: 0.02552805282175541\n",
      "Minibatch loss at step 900: 0.009902223944664001\n",
      "Minibatch loss at step 950: 0.012368336319923401\n",
      "Minibatch loss at step 1000: 0.007131851278245449\n",
      "Minibatch loss at step 1050: 0.007247623056173325\n",
      "Minibatch loss at step 1100: 0.007934832945466042\n",
      "Minibatch loss at step 1150: 0.03873901814222336\n",
      "Minibatch loss at step 1200: 0.017590340226888657\n",
      "Minibatch loss at step 1250: 0.0075094979256391525\n",
      "Minibatch loss at step 1300: 0.007515665143728256\n",
      "Minibatch loss at step 1350: 0.008320826105773449\n",
      "Minibatch loss at step 1400: 0.006819882895797491\n",
      "Minibatch loss at step 1450: 0.019481776282191277\n",
      "Minibatch loss at step 1500: 0.009255731478333473\n",
      "Minibatch loss at step 1550: 0.006817718036472797\n",
      "Minibatch loss at step 1600: 0.008163664489984512\n",
      "Minibatch loss at step 1650: 0.0067938948050141335\n",
      "Minibatch loss at step 1700: 0.01846810057759285\n",
      "Minibatch loss at step 1750: 0.008429876528680325\n",
      "Minibatch loss at step 1800: 0.006432469468563795\n",
      "Minibatch loss at step 1850: 0.0063144429586827755\n",
      "Minibatch loss at step 1900: 0.0064645069651305676\n",
      "Minibatch loss at step 1950: 0.0065439725294709206\n",
      "Start training....\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Minibatch loss at step 0: 0.007180351763963699\n",
      "Minibatch loss at step 50: 0.008131018839776516\n",
      "Minibatch loss at step 100: 0.012926774099469185\n",
      "Minibatch loss at step 150: 0.006501078139990568\n",
      "Minibatch loss at step 200: 0.030760888010263443\n",
      "Minibatch loss at step 250: 0.007352069485932589\n",
      "Minibatch loss at step 300: 0.007668561767786741\n",
      "Minibatch loss at step 350: 0.012773077934980392\n",
      "Minibatch loss at step 400: 0.008886835537850857\n",
      "Minibatch loss at step 450: 0.006652345880866051\n",
      "Minibatch loss at step 500: 0.0063324724324047565\n",
      "Minibatch loss at step 550: 0.006744133308529854\n",
      "Minibatch loss at step 600: 0.00639472296461463\n",
      "Minibatch loss at step 650: 0.006220477167516947\n",
      "Minibatch loss at step 700: 0.0063917129300534725\n",
      "Minibatch loss at step 750: 0.0063537550158798695\n",
      "Minibatch loss at step 800: 0.006073051132261753\n",
      "Minibatch loss at step 850: 0.00592790637165308\n",
      "Minibatch loss at step 900: 0.007878067903220654\n",
      "Minibatch loss at step 950: 0.007489531300961971\n",
      "Minibatch loss at step 1000: 0.007604056969285011\n",
      "Minibatch loss at step 1050: 0.00581445824354887\n",
      "Minibatch loss at step 1100: 0.013567663729190826\n",
      "Minibatch loss at step 1150: 0.0060863555409014225\n",
      "Minibatch loss at step 1200: 0.006346962880343199\n",
      "Minibatch loss at step 1250: 0.005769133567810059\n",
      "Minibatch loss at step 1300: 0.006751528009772301\n",
      "Minibatch loss at step 1350: 0.00855825375765562\n",
      "Minibatch loss at step 1400: 0.00566472765058279\n",
      "Minibatch loss at step 1450: 0.005892476998269558\n",
      "Minibatch loss at step 1500: 0.0058835954405367374\n",
      "Minibatch loss at step 1550: 0.006313519552350044\n",
      "Minibatch loss at step 1600: 0.005937494337558746\n",
      "Minibatch loss at step 1650: 0.024975381791591644\n",
      "Minibatch loss at step 1700: 0.0063400110229849815\n",
      "Minibatch loss at step 1750: 0.011440441943705082\n",
      "Minibatch loss at step 1800: 0.006085389759391546\n",
      "Minibatch loss at step 1850: 0.02342228963971138\n",
      "Minibatch loss at step 1900: 0.008062062785029411\n",
      "Minibatch loss at step 1950: 0.00583556666970253\n",
      "Minibatch loss at step 2000: 0.0072208489291369915\n",
      "Minibatch loss at step 2050: 0.005897222086787224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 2100: 0.005867016036063433\n",
      "Minibatch loss at step 2150: 0.011057939380407333\n",
      "Minibatch loss at step 2200: 0.010932499542832375\n",
      "Minibatch loss at step 2250: 0.008525611832737923\n",
      "Minibatch loss at step 2300: 0.005935034714639187\n",
      "Minibatch loss at step 2350: 0.010989145375788212\n",
      "Minibatch loss at step 2400: 0.015233572572469711\n",
      "Minibatch loss at step 2450: 0.005936314817517996\n",
      "Minibatch loss at step 2500: 0.007299234624952078\n",
      "Minibatch loss at step 2550: 0.00842951238155365\n",
      "Minibatch loss at step 2600: 0.00927777960896492\n",
      "Minibatch loss at step 2650: 0.005728002171963453\n",
      "Minibatch loss at step 2700: 0.0068631223402917385\n",
      "Minibatch loss at step 2750: 0.006794311571866274\n",
      "Minibatch loss at step 2800: 0.005702583119273186\n",
      "Minibatch loss at step 2850: 0.0066250162199139595\n",
      "Minibatch loss at step 2900: 0.006104726344347\n",
      "Minibatch loss at step 2950: 0.006423786282539368\n",
      "Minibatch loss at step 3000: 0.00523808877915144\n",
      "Minibatch loss at step 3050: 0.005619672127068043\n",
      "Minibatch loss at step 3100: 0.028148788958787918\n",
      "Minibatch loss at step 3150: 0.013876087963581085\n",
      "Minibatch loss at step 3200: 0.007567092310637236\n",
      "Minibatch loss at step 3250: 0.00852083507925272\n",
      "Minibatch loss at step 3300: 0.006800511851906776\n",
      "Minibatch loss at step 3350: 0.006832593586295843\n",
      "Minibatch loss at step 3400: 0.007313709706068039\n",
      "Minibatch loss at step 3450: 0.006907009053975344\n",
      "Minibatch loss at step 3500: 0.006462816148996353\n",
      "Minibatch loss at step 3550: 0.006450486835092306\n",
      "Minibatch loss at step 3600: 0.04674004763364792\n",
      "Minibatch loss at step 3650: 0.028160221874713898\n",
      "Minibatch loss at step 3700: 0.0061476328410208225\n",
      "Minibatch loss at step 3750: 0.005834169685840607\n",
      "Minibatch loss at step 3800: 0.027340741828083992\n",
      "Minibatch loss at step 3850: 0.005668408237397671\n",
      "Minibatch loss at step 3900: 0.00550979794934392\n",
      "Minibatch loss at step 3950: 0.009856260381639004\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i, vals in enumerate(learning_schedule):\n",
    "    ITERATIONS = vals[0]\n",
    "    LR = vals[1]\n",
    "    if i == 0:\n",
    "        model.learning_rate = LR\n",
    "        #losses = model.train(x_sample, y_sample_oh, TRAIN_BATCH_SIZE, ITERATIONS)\n",
    "        losses = model.train(x_train, y_train_oh, TRAIN_BATCH_SIZE, ITERATIONS)\n",
    "    else:\n",
    "\n",
    "        #losses_new = model.train(x_sample, y_sample_oh, TRAIN_BATCH_SIZE, ITERATIONS, import_from_previous = True)\n",
    "        losses_new = model.train(x_train, y_train_oh, TRAIN_BATCH_SIZE, ITERATIONS, import_from_previous = True)\n",
    "        losses_new[:,0] += losses[-1,0] + TRAIN_BATCH_SIZE\n",
    "        losses = np.vstack((losses,losses_new))\n",
    "end_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 8144.678204059601s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training time: {}s\".format(end_time - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3XtsHNXdPvDnu2vHztVrJw7EEBI2JCkOUHCcV1AJAqoTRKVSlcahlBap8MahBamVqOKXit5oRWvzaysVJLSBQtSiSk1cVHqhlzgFSimoxCYlhZKALxAIufmWi+Prfn9/zMxmvNld7+7MeGad5yOtNpmZPXv2ZLLPnpkzZ0RVQUREFDQhvytARESUCgOKiIgCiQFFRESBxIAiIqJAYkAREVEgMaCIiCiQGFBERBRIDCgiIgokBhQREQVSkd8VCIIFCxbo0qVL/a4GEdG01dbWdkxVK3N5DQMKwNKlS7F7926/q0FENG2JyHu5voaH+IiIKJAYUEREFEgMKCIiCiQGFBERBRIDioiIAokBRUREgcSAcmB0dBRdXV04ceKE31UhIpp2GFAOdHd3IxqN4tlnn/W7KkRE0w4DyoFwOAwAiMfjPteEiGj6YUA5EAoZzTc+Pu5zTYiIph8GlANWD4oBRUTkPgaUAwwoIiLvMKAc4DkoIiLvMKAc4DkoIiLvMKAc4CE+IiLvMKAcYEAREXmHAeUAA4qIyDsMKAesc1AcJEFE5D4GlAPsQREReYcB5QADiojIOwwoBxhQRETeYUA5ICIQEZ6DIiLyAAPKoVAoxB4UEZEHGFAOhcNhBhQRkQd8DygRiYjIDhHpEBE1n5vyKKdBRNrMMtpEpMGL+iZjQBERecPXgBKRCIAuABsA9ANoMVdtEZG2HMqJAYgBiJplRAHE8gm6XIXDYZ6DIiLygN89qCYAEQCbVXW1qtar6jIYIVMjIhsmK0BEogAaALSrarlZRjmAThhBV+PlB+A5KCIib/gdUHUA+lV1a9LyH5rPa7Ioo9F83pS0fHPSsyd4iI+IyBtFPr9/P4DWDOsjWZRhhVy7faGqtooIANTmX73JMaCIiLzha0Cp6uo0q6xez84siokCaE+zrtNc7xkGFBGRN/zuQSWY55tuBVADI1S2qmpL5lcl9KZZ3o80AWWO8msAgIsuuii3ytqEQiEOkiAi8oDf56Ds1sEYzWcFSsdkLzBHAQJGEKXSm7RdgqpuVdVaVa2trKzMo7oG9qCIiLwRmIBS1c2qKgCWwTgv1TTZMHFVtYIp3bmqiqTtXMeAIiLyRmACyqKqnaq6DkavKNuLbSvSLI8gfe/KFQwoIiJv+BZQIlIjIjERqUuzSSeyG8WXaSBE1FzvGZ6DIiLyht89qAYA9WnWRZFd76cVQCT5glxb8GUaxu4Ye1BERN7wLaDM65b6ATSYs0EkiMgWGL2n7UnLIykGPMTM5+TzVU1J6z3BgCIi8obfw8w3AdgBoENEWnFmWHiN+WdrlgirR7QTxjVPieunVLVdRFoAbDDn72uFcfFuDYyh6p4e4mNAERF5w9dDfOZ1TqthhEotjGHmANBszquX1QAHVa2HEWYRAFbvq1FVPZ3mCOBksUREXvG7B2Ud6luXxXatACTD+mYAzS5WLSucLJaIyBt+D5IoeDzER0TkDQaUQwwoIiJvMKAc4jkoIiJvMKAc4jkoIiJvMKAc4iE+IiJvMKAcYkAREXmDAeUQA4qIyBsMKIc4WSwRkTcYUA6xB0VE5A0GlEMMKCIibzCgHGJAERF5gwHlEC/UJSLyBgPKIV6oS0TkDQaUQzzER0TkDQaUQwwoIiJvMKAc4jkoIiJvMKAc4jkoIiJvMKAc4iE+IiJvMKAcYkAREXmDAeUQz0EREXmDAeUQz0EREXmDAeUQD/EREXmDAeUQA4qIyBsMKIcYUERE3mBAOcQbFhIReYMB5RB7UERE3mBAOcSAIiLyBgPKoXA4DAA8zEdE5DIGlEMMKCIibzCgHAqFjCbkYT4iIncxoByyelAMKCIidzGgHGJAERF5gwHlEM9BERF5gwHlEM9BERF5gwHlEA/xERF5gwHlEAOKiMgbDCiHGFBERN5gQDlknYPiIAkiIncxoBxiD4qIyBsMKIcYUERE3mBAOcSAIiLyRiACSkSaRKRDRNR8jolIJMcyGkSkzSyjTUQavKqvHc9BERF5w/eAEpEOAFsAVABoAdAPoAFAV7YhJSIxADEAUbOMKICYiDR5Umkb9qCIiLzha0CJyBaYoaKq5apar6qrAWwGEAGwI4syojACrd1WRjmATgBbRKTGw4/AgCIi8ojfPahbzedN9oWquhVGwNRlUUZjqjJghJz92RMMKCIib/gdUFEA/aran2JdJ5DoIWVSZ5bRbl+oqq3mH2sd1zIDThZLROSNIjcLE5F5qno8h5d8EsY5p1RqAUBVOycpIwqgPc26TnO9ZzhZLBGRN/LqQYnIlSLymIgsNf9eJiKvAegTkXERuS+bclS1PVUAmYMeIjAGPGSjN83yfrMcz/AQHxGRN3IOKBH5JIweSwPOfPk3AVgNYBeAbgDNIvLZPMqOiMgOs+xOnH1e6aztzT+m64X1Jm1nf22DiOwWkd1Hjx7NtaoJDCgiIm/k04NqBKAA1qvqHnPZRgA7VXW9qi4DMADg/lwKNa9b6gOwAUArgNVpzk0l2Nan6yVVJG1nf+1WVa1V1drKyspcqjoBz0EREXkjn4CqBdCqqrsAQESughEQMds22wEsy6Yws9e003x9P4B6VV03WTglqUizPIL0vStX8BwUEZE38hkkkfylXwejR9VqW1aB7M/97AJQA+NaqPo86pNpIESmARSu4CE+IiJv5NODeh0Tr0/aDKAzafReDcxh4pmYMz3UAGjOM5wAIxgjyRfkikidbb1nGFBERN7IJ6BiAMpF5B0ReQfAxeYyiMgnbcuyGYHXAOMapsZJt0TicGByz8w6tJg8rVFT0npPMKCIiLyR8yE+Vd1qhsT/wRwKrqr/z1y9Dsa5p52qmnGQhHkBbgRAv4i0ZXi/1eb2dQB2wjhkt9q2vl1EWgBsMMtphdHDqwGwNYvrqBzhZLFERN7I60JdVW0G0JxiVQxATFW7sijGOm8UgREmKYlIJIvRfPXmvH6bYUw82wmg0aynp9iDIiLyhqszSQDoyXYmCXMqIsm24Mm2zxCanmJAERF5w9eZJKYDBhQRkTcCNZNEIeI5KCIibwRmJolCxR4UEZE3fJ9JotAxoIiIvJFPQLk9k0RBY0AREXnD15kkpgNOFktE5A2/Z5IoeJwslojIG77NJDFd8BAfEZE38roOSlWbVbVCVUOqutG2KgZgmare6E71go8BRUTkDVdmkhCReap6PMspjqYVBhQRkTfy6kEBgIh8wzwPNY4zM0i8cy7NIgHwQl0iIq/k1YMypzWqgXFB7i6cuWlgLYxZJG5V1f9xrZYBxh4UEZE3cg4oEfkRjGmNtqrq3SnWxwBsEpGHVPWbLtQx0BhQRETeyOcQXx2AjlThBACquhlGj2qdk4oVCgYUEZE38gmoGhiTxWbSigz3eJpOeA6KiMgb+QSUdb4pk1qcYzNJsAdFROSufAJqF4CadKP1RGQTjN5Ta6r10w1nkiAi8kY+M0lsFpE6GKP17oYRRB0wZpCoM5/7YNyWY9oTEYRCIQYUEZHL8r1QtwbG7dU34ezbamwF0Jjtrd+ng3A4zHNQREQuyyugVHUAxizmm0XkYpi34DgXZ5IAwB4UEZEHHE91lCqUrPNQqvoVp+UXgnA4zIAiInJZ3lMdTWIdgAaPyg4cBhQRkfu8CqhzCs9BERG5jwHlAp6DIiJyHwPKBTzER0TkPgaUCxhQRETuY0C5gAFFROS+SYeZi8j/5lHuOTFRrCUUCnGQBBGRy7K5DmorAAUgWZZpbav5VqrQsAdFROS+bAJqs+e1KHAMKCIi900aUKr6+FRUpJAxoIiI3MdBEi7gOSgiIvcxoFzAHhQRkfsYUC5gQBERuY8B5QIGFBGR+xhQLuBksURE7mNAuYCTxRIRuY8B5QIe4iMich8DygUMKCIi9zGgXMBzUERE7mNAuYDnoIiI3MeAcgEP8RERuS8QASUiDSLS5+C1bSKi5nOD2/WbDAOKiMh9gQgo5DljuojEAMQARAG0mM8xEWlysW6TYkAREbnPt4ASkYiI1InITuRxg0MRiQJoANCuquWqWq+q5QA6AWwRkSm7aSIniyUicp+fPag+ADsB1OX5+kbzeVPS8s1Jz55jD4qIyH3Z3LDQK/W2P+dzz6k6AP2q2m5fqKqtIgIAtQ7qlhMGFBGR+3wLKFVtsf5snjOqyLGIKID2NOs6zfVTggFFROS+oAySyFdvmuX9ACKZXmiO/tstIruPHj3qqBI8B0VE5L6CDCgRscKnP80mvUnbnUVVt6pqrarWVlZWOqoPe1BERO4ryIBSVSuY0gVQRdJ2nmJAERG5ryADyibdeasI0veuXMeAIiJyXyEHVKaBEFFz/ZTgZLFERO4r5IBqBRBJviBXROps66dEUVERRkZGpurtiIjOCQURUOasE8nnm2Lmc/K0Rk1J6z03b948HD9+fKrejojonBD4gDJ7RH0AdtmXmxfotgCoMyeJbRKRNhjTJm1V1Sk7xFdWVobh4WEMDw9P1VsSEU17gQ+oTFS1HsaURxEAW8znRlWdsmmOACASMTp3AwMDU/m2RETTmp9THSWo6rIM61oBSIb1zQCavahXtsrKygAYAbVw4UI/q0JENG0UdA8qKOwBRURE7mBAucAKqP7+Kbv0ioho2mNAuYA9KCIi9zGgXMCAIiJyHwPKBRzFR0TkPgaUC+bOnQuAAUVE5CYGlAvC4TDmzp3LgCIichEDyiVlZWUMKCIiFzGgXMKAIiJyFwPKJWVlZbwOiojIRQwol0QiEfagiIhcxIByCQ/xERG5iwHlEgYUEZG7GFAuYUAREbmLAeWSsrIyjIyMYGhoyO+qEBFNCwwol3A+PiIidzGgXGLNx8eh5kRE7mBAuYQ9KCIidzGgXMKAIiJyFwPKJQwoIiJ3MaBcwoAiInIXA8olFRUVAIBjx475XBMioumBAeWSOXPmYNGiRXj77bf9rgoR0bTAgHJRdXU13nrrLb+rQUQ0LTCgXGQFlKr6XRUiooLHgHLRqlWrcPLkSRw4cMDvqhARFTwGlIuqq6sBAG+++abPNSEiKnwMKBdZAcXzUEREzjGgXDR//nycd9557EEREbmAAeUy+0i+N954A9/4xjcwPj7uc62IiAoPA8plq1atwt69e9HW1obPfvaz+PGPf4zdu3f7XS0iooLDgHLZV77yFcyePRu1tbXo7u4GALS2tuLdd9/F7bffjoMHD/pbQSKiAlHkdwWmm+rqarz88sv4/Oc/j9tvvx2//OUvsWvXLnR3d+NXv/oVurq68MILL2DGjBl+V5WIKNAYUB5Yvnw52traAAAHDx7EI488gtdeew2rVq3CK6+8gm9961toamryuZZERMHGQ3weq6urw8jICE6ePInHH38cn/vc57Bt2zbE43G/q0ZEFGgMKI9de+21KC4uRnV1Na6++mrccsstOHLkCP71r3/5XTUiokDjIT6PzZ49G48++iiWL18OEcFNN92EcDiM3//+97j66qv9rh4RUWAJJzYFamtrdSqHgl9//fXo7e3FG2+8MWXvSUTkJxFpU9XaXF7DQ3w++PSnP429e/cmhqETEdHZGFA++NSnPgXAuD6KiIhSY0D54GMf+xgWLlyIF1980e+qEBEFViACSkQaRKRNRNR8bvCjjKkiIli7di1efPFF3tyQiCgN3wNKRGIAYgCiAFrM55iIZH0lqxtlTLW1a9fiwIED6Orq8rsqRESB5GtAiUgUQAOAdlUtV9V6VS0H0Algi4jUTEUZfrj++usBgIf5iMgXqhr4Izh+96AazedNScs3Jz17XcaUq66uxoIFC/Dkk0/iiSeewEcffYT9+/fjzjvvdCW0RkZGcPToUQBAd3c3nnrqKZw6dcpxuW45efIknnzySTz88MPo7e31uzpZO3bsGN5//32/q5FSV1cXvv/972NgYMDvqiAej+PkyZN+V4MyuOOOOxCNRvG3v/3N76qk5et1UCLSAaDC7PEkr1MYvaLVXpcx1ddBWb761a/iscceAwAUFRUhFAphZGQEM2bMwHe/+12cOnUKVVVVWLlyJXp6ehAOhzF//nxUVFRg1qxZCIfDKCoqQjgcnvDn9957D1/84hfxzjvv4N5778W2bdvQ09ODBQsW4Atf+AKuu+46LFy4EFVVVViyZAlCoRDi8TiGhoawf/9+HDp0CENDQxgeHsbQ0BBGR0dx5ZVXora2FqFQCENDQzh06BAOHjyIw4cPIxqN4siRI/ja176Gyy67DI888ggikQhUFe+99x7uv/9+qCoeeughXHDBBXj88cfx4IMP4vjx4wCAefPm4ZZbbsGNN96ItWvX4s9//jNefvll3HbbbaiqqsLevXvR09ODRYsWYd26dZg9ezbGx8dx5MgRhEIhzJw5E6WlpSguLoaIJNq3p6cHL774Ij744AOICG6++WbMnz8f7777LlasWIFZs2ZN+Pc4ceIEioqKUFpaChHB8PAwjh8/jgULFgAAtm/fjrvuugunTp3CkiVLsHbtWlx33XWYO3cuPvzwQxw8eBCLFy/GbbfdhsrKygllx+NxvPvuu6iqqsKcOXOy3kd+97vf4Tvf+Q4GBwdx6aWX4qGHHsKyZcswPj4+of5Hjx7FNddcg46ODixfvhzbtm3DNddcM6E9rO1+85vfoKamBmvWrDlr/f79+7F7927ceOONmD9/ftb1BIDTp09jfHwco6Oj+MxnPoO9e/fimWeewQ033AAAOH78OIqLizFz5sycys3GwMAAwuFwTm1r19PTg/vuuw8LFizAgw8+mKjj2NgYfvrTn+LDDz/EN7/5TZx33nlpy4jH4xCRs9p0bGwM77zzDkpLS3HxxRfnVb9Unn/+edxxxx249tpr8e1vfxsrV648673T2b59O2699VZEIhH09/fjgQcewPe+9z2oKh544AH84Q9/wFNPPYXa2jOXLcXjcYRC+fdp8rkOyu+AShsgmYLH7TL8CijA+E/d1dWFn//85xgaGsI999yDu+66C6+++ipEJO8ueGVlJdasWYPnnnsOK1aswA9/+EP84he/wF//+lecPn06rzJLSkoQDocxODiYcv3SpUvx0UcfYXR0dMJcg2VlZQAw4Zf9TTfdhAceeABz5sxBc3MznnvuOfT19U14r+Hh4bPeIxwOY9asWTh9+jTGxsYmrLOH1fDwcMpf8FYYFxUVoby8HP39/aioqAAAHD58GAAwY8YMzJ07F319fYjH45gzZw7Gx8dx+vRpfOITn8DGjRvx0ksv4e9//3uil2q9bmRkBIDR/uXl5YkfDQcPHkz8yLjkkksSP0isB3DmkIv1GBsbw3//+19UV1fj8ssvx1/+8hf09/cDMAbaLF++HPPmzcPo6CgOHz6M/v5+PPzww/jBD36Aw4cP4+KLL0ZFRQVCoRDC4TBEBHv27En8+1dVVaGqqgpjY2MYHR1FcXEx9uzZAwAoLi7GJZdcglmzZmH27NkIhUIYHx9P+zh9+nTiur5IJIITJ05g8eLFOHDgAFatWoXe3t5Ez3P+/PlYvHgx5s2bl/gskz0AYHR0FH19fVBVzJgxAyUlJSgpKcGJEyfw2muvIRQKYc2aNZg7d27i38T+hZ3uzwDw+uuv49ixYxgbG8P555+PU6dOQURQVlaGAwcOIBQKYdasWbjiiiswe/ZsnDx5EiKCkpISFBUVobOzEx0dHQCAOXPm4Pzzz8d5552HEydO4O23307sFx//+MdRVlaGwcFBnDp1CoODgxARLFmyBKWlpRgdHU38W5SWlkJVEY/HoaoQEYRCocT3ws6dO3HhhRfiyJEjGBwcxAUXXJDYH0pKSlBaWoqSkpLEa+yP119/HStWrEBrayu+/vWv46mnnsJVV12FeDyOf//73ygrK8PQ0BDWrVuHoaEh7Nu3D+vXr8cTTzxx1v+pbBVqQLWq6roU69oA1Khqxp8E+ZZhjvJrAICLLrpo9XvvvZfnp3Df2NgYuru7sWTJEnz44Yfo7OxEZWUlVBW9vb3o6elJ/FodGxs76zkUCmHjxo1YtGgRXnnlFVRXVydCYmhoCP/5z3/Q19eHDz74IPGlEQ6HUVxcjGXLlmHx4sUoLS1N7OAign/84x/Ys2cP4vE4ysvLUVVVhUWLFqGyshJvv/02jh8/ji9/+cvo6urC008/nfhSExHceeedEBFs27YNAHDllVeirq5uwpfE+Pg4du/ejRdeeAGXX345brjhBjzzzDMYGRlBTU0NKisrsW/fPjz//PM4efIkZs6ciQsvvBCAEfL2x9DQEEpKSrBw4UJcd911WLlyJfr7+/HrX/8aIyMjWLlyJfbu3Yve3l5EIhH09PQgHo9jxYoVUFUMDAxgYGAAlZWVqKioQFdXF4qKinDJJZfgzjvvTNwqRVWxb98+jI2NoaqqCuXl5XjzzTfx29/+FgcOHMDAwEDi36SiogLXXHMNuru7sW/fPsTj8cRjfHw87RfzmjVrcN9992HGjBk4evQoYrFYor3eeOMNDA0NoaioCMXFxWhoaMD69etx/PhxbN++HX/6058wPDyM8fHxxHtFo1E0NDSgvb0dL730Eo4ePYri4mIUFxfj1KlTuPrqq1FXV4dnn30W3d3diS/SeDye6KnbH1YAz5gxA8uXL4eq4q233sI999yDq666Co2Njfjoo48wZ84cXHHFFYjH43j//fdx4MABDA4OnhXKyQ+rnVU18aMiHA5jeHgYIyMjGB4eRjgcxtq1azE6Oop//vOfGB0dTbzOku7PlvLycvzoRz9CT08Pfvazn+Giiy5CPB5HZ2cn7r77blRXV6O5uRldXV0YHBxM9NSselx44YW49NJLEQ6HMTAwgEOHDuHQoUOYOXMmLr/8clx22WU4cuQI/vjHPyIej2P27NmJ8Lf+v1vBVFxcjLGxMZw+fTrxA8YKJSus4vE4Vq1ahUcffRSDg4NoaWnBq6++iuHhYRQVFWFkZCRxFMT+Ousxd+5c/OQnP8HKlSuhqnjsscfw9NNPQ1WxadMm3Hzzzbj33nuxf/9+FBcXY8WKFVi/fj2+9KUv5f29VlABJSIRAH0AWlS1PsX6nQDqAJSrar9XZQD+9qCIiM4FBTXVkS0wImk2qUjazpMyiIgomPwexQeYIZJCBEC2weJGGUREFCB+B1QnjItqU4ma66eiDCIiChi/A6oVQCT5YloRqbOtn4oyiIgoYPwOqJj5nDwlUVPSegDGoAhzYETeZRARUWHwNaBUtR3G3Hl15gSvTdbQcABbVTVxeM7sEfUB2JVvGUREVDj87kHBHB7eCGNAwxbzuVFVs56iyI0yiIgoWHjLd/A6KCIirxXUhbpBIiJHATiZSmIBgGMuVedcwTbLHdssd2yz3HnVZktUtXLyzc5gQLlARHbn+svgXMc2yx3bLHdss9wFqc18PwdFRESUCgOKiIgCiQHljq1+V6AAsc1yxzbLHdssd4FpM56DIiKiQGIPioiIAokBRUREgcSAypOINJhTK6n53OB3nbxmTiPVYX7mDhGJpZgbESLSZ26T6rElxfZZt2UhtXtQ2qEQ2sycZzNdW9kfG2yvCUT7TjWzbn1ZbOPrvuRKG052y2U+Ut6GOgZAYcwNuMN8VgBNftfNw8/ckfSZ22x/jyRtay1vS/HYkG9bFlq7B6EdCqnN0rST9bDqXRek9vWxnfoyrPd9X3KrDX1v7EJ7wLjHlAJoS1pufYHX+F1HDz7zFvOz7Uha3mAu35mifSbdEXNpy0Jr9yC0Q6G12SRt1HEu72cw5hetA7DT+uIP6r7kZhv6vuMV2gNnfhnUJC2vM5fH/K6jB5/Z6i1FUqzrAKAp2mFDFuVm3ZaF1u5BaIdCa7MM7dNk1jcapPad4jbQpEe6gPJ9X3KzDX3f+QrtYX4hp9s5zvrVMB0eMLrn6T6z9Ysuav69IdXO6bQtC63dg9AOhdZmaepp/RrfErT2neJ22GB7ZPr/6Pu+5GYbcpBE7jLdRj7T7ecL2ScBrE6zrhYA9Mx9t5aZz3W2E6TpBlTk0paF1u5BaIdCa7NUYgD6VbU5aXkQ2nfKqGqL9QDQm2HTIOxLrrUhAyo/6XaQfhjHiqcVVW3XFDd+FJEYjM/bYlts7XzWHY2tdQ0AulJ8eeTSloXU7kFph0JqswlEpAbGYaHGFKuD0r5BFIR9yZU2ZEDlwLbT96fZpDdpu2nJHBK8A8aXQSeATbbVERjts05VV6tqvaouA9BsrnvcKsPcftK2LNB297UdCrTNkjXB6D2lmnqH+1mSIOxLbrdhUTYbkUFV+0UESP8LoMLabsoqNcXMaxli5l9bAdTbP6+qrkv1OlVtNF+7wfx7Tm1ZaO0ehHYotDazm6T3FIj2DZqg7EtutiF7UPmpSLPc+lU37Zi/jnbCPCcAI5jW5fiftdUsy34MOpe2nC7tPpXtUKhtttl8zmfi0nN9PwvCvuRKGzKgcpfpJF+mk4OFbheMX7QtqlpunqzNl3V8Ope2nI7t7nU7FHKbNQBoddhbORf3syDsS661IQMqd60AIuYhiAQRqbOtn1ZEpAlADYBmVa3PsF3UHE21I80mNTDOKVhfOrm0ZcG0e4DaoWDazM42nVHK9gtQ+wZREPYl99rQjzH9hfyAsfMrbFe1m8uti1mjftTL48+c9rqLFNtaV4vXJS23ZqNosi3Lui0Lrd2D0A6F1ma2+sUmq18Q2tfnfSvddUa+70tutqHvO2MhPmD8slOzwZtsDV8QV+bn+FmtCyXTzXnWhokX6Vk7p8K4iHeH7cvkrAv0cmnLQmr3oLRDIbWZrc4TZicJcvv62D6Z5uLzfV9yqw19b+xCfcD4pWb9h+hA0pXu0+WBM9OTTPaI2F4ThfEruMO2k6Ztn1zaspDaPSjtUGBtFrFCp1Da14c2yhhQQdmX3GhD3lGXiIgCiYMkiIgokBhQREQUSAwoIiIKJAYUEREFEgOKiIgCiQFFRESBxIAiIqIsx95GAAAD20lEQVRAYkARpWDdodXveuRCRHaICC9spGmDAUWUJRGpM4Nrw+RbT/96EHmNAUU0fWwCsMzvShC5hXfUJZom1Li9RCHcUI8oK+xBEWXBvJvwTvOvKc/1iMgWEWkzD7/1iUgs6a6uMJf12f6s5i3Krfsc7RCRDlsZO+xlZKpHunNQ5vtYZbaZ9/dKtY1VrybzvdV83VmHEkWkIemz7rTd74fIFQwoouw04cztx7fizC3JAQAiYt1WwFrfCeOusB3JN24zt28y13cC6DVDqAPABnNZC4w7wm4A0CYikWzqkfQeEXOgRwOMnlULjNnCt5j1TfWamLn9drP8KIwgrLNtswXGLOJRs8zdMGa935nqsxLlze+p4/ngI4gPmLcISFpm3XpkQ9Jy6yZ5yTfPs+5ZZL9flnUzvj4ANSmWp7sB34Ys6rEDtvso2crckrTdWcttyzow8dYp1nvFbMv6MrRNIO6ZxMf0eLAHReTc/TBuY73b7LVEzB5Pp7m8xtYDsjSqarvt7zEA9aqafDtsa5uKPOrVAKBTVZvtC1V1M4weVareV6OeuVU6bPWxv3/yZ7G2W40zvUgixzhIgsi5CIweRF+GbSowcQDDhCAyw6odMA7NAaiF0QNLewgvE9t5q+TAs1iH5ZK1p1iWrAXABvPwYQxAq6q2JwUukWMMKCIHkoIgU++h1/4XVe1MKidivn4jzvRQWmEExoSBFlmyykh3sXGn9b72HlNyPVNR1XrzPNRms84QkX4Y560ak8ojyhsDisgZ6wu9P8XhuVzsgtFj2grjPI7Vm6qBMVAiV1ZIpLsuKgokhqYnZBsu5mHDZjNY62CEVQOMnt/qPOpLdBaegyJyQM9ce5RyiLU5TDvjlEnml3wNgBZV3Zx0qCyfc0/2Hlq6od+1MHtRuTCHwjdZo/pUtV9VW1R1HdKfbyPKCwOKyLmtACIissO+0DwMFoVxniYbE77YbYf9nNQral1nZSs3Zr5XtvVKZg0zT5ayV0aULwYUUe7ut1/sqqqNMHojG8weU8x2XVR78ii6ZOYXeiuAOvNi2y1miHThzCHEzSkuhJ1QjxQaYfTuYuZFtTHbdVGT1itNXa2RiVHzs+6wXeQbNd+TyBUMKKIsmeeYWmEcjmtIWrcMQDOMQGiA0UNpVtVsz8fUw+jx1MEItiiATeahs63me9ZPVo+kOvUDuNh8fQRnLtjNpV6pyl0H47MCxvmxjTACuj6f0CNKR1Q5Oz8REQUPe1BERBRIDCgiIgokBhQREQUSA4qIiAKJAUVERIHEgCIiokBiQBERUSAxoIiIKJAYUEREFEj/H6UxEveZIgdrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = losses[:,0]\n",
    "train_loss = losses[:,1]\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "utls.remove_tex_axis(ax, ytick_fmt=\"%.1f\")\n",
    "ax.plot(iterations, train_loss,'-k')\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Loss')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test network predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Average test loss: 1.781084656715393\n"
     ]
    }
   ],
   "source": [
    "model.test(x_test,y_test_oh, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss was 2.25 for MLP, so it's an improvement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Test sample digit: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "example = np.random.choice(n_test)\n",
    "\n",
    "sample = x_test[example]\n",
    "label = y_test_oh[example]\n",
    "feed_dict = {model.input: np.expand_dims(sample, axis=0), \n",
    "             model.ground_truth: np.expand_dims(label,axis=0),\n",
    "            model.is_training: False}\n",
    "\n",
    "digit = np.where(label==1.0)[0][0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "    saver.restore(sess, './model')\n",
    "    prediction = sess.run(model.prediction, feed_dict = feed_dict)[0]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(2*5,5))\n",
    "axs = axs.ravel()\n",
    "\n",
    "ax = axs[0]\n",
    "utls.remove_tex_axis(ax)\n",
    "ax.imshow(x_test[example,:,:,0],cmap=cm.binary)\n",
    "ax.set_title('Test example')\n",
    "\n",
    "classes = np.arange(10)\n",
    "width = 0.5\n",
    "\n",
    "ax = axs[1]\n",
    "\n",
    "ax.bar(classes, prediction, width, color='Black')\n",
    "utls.remove_tex_axis(ax,ytick_fmt=\"%.2f\")\n",
    "ax.set_xticks(classes)\n",
    "ax.set_xticklabels([str(x) for x in np.arange(10)])\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Digit class')\n",
    "ax.set_title('Network categorical distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "print('Test sample digit: {}'.format(digit))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
