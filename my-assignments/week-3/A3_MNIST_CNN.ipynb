{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Convolutional Neural Network in Tensorflow\n",
    "\n",
    "Author: Juvid Aryaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "sys.path.append(\"..\")\n",
    "import utls\n",
    "utls.reset_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST is a dataset of 28$\\times$28 handwritten digits. The dataset comes shipped with tensorflow, so let's load it up and have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand the final dimension to a single channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train,axis=3)\n",
    "x_test = np.expand_dims(x_test,axis=3)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (10000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEFCAYAAAAFVJmvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAADCxJREFUeJzt3U9oXOUax/HfcxEX2RiHRnGVMNm4jrNUEU13rSIkXFChKNiAIu6MBV0JytxVXcnkIi4qblr8txExd2FdidMuFMSNQ+uigil1Fu6fu5g3T04nM+9JMieZmc73A6XJeebMvH1TfjnnPc+cMXcXAEjSv8Y9AACTg0AAEAgEAIFAABAIBACBQAAQCAQA4b6qnsjMViQ1JHUk1SV13H27qucHcPwqCQQzq0tquvvpwrbLZtZx904VrwHg+FV1hLAhqdW3rSWpKWk9t+OpU6d8aWmpomEAGOTatWu33X2h7HFVBcKa9gdCW9J3ZTsuLS2p3W5XNAwAg5jZzYM8buRFRTObV2/N4E5xu7t3U70+6msAOBlVXGWoSXsBMACBAEyJKgJh/rA7mNl5M2ubWXtnZ6eCIQCowlj6ENx9y90b7t5YWChd5wBwQioLhLSWAGCKVREIu30GteLGQkDQhwBMiZEDIS0mdrR/LaEmqUtjEjA9qjpl2FavbbloJW0HMCWqCoRN7e9I3EjbAUyJSjoV3b1rZptm9pb23tzU5HQBmC6VvdvR3a9Lul7V8wE4edwPAUAgEAAEAgFAIBAABAIBQCAQAAQCAUAgEAAEAgFAIBAAhMpal4FdZnbk+ttvv53d9/333z/SmHAwHCEACAQCgEAgAAgEAoBAIAAIBAKAQCAACPQhzKCyj88r+zTuzz//PFsfpQ/hiy++yO5LH8Lx4ggBQCAQAAQCAUAgEAAEAgFAIBAABAIBQKAP4R7V7XaH1s6dO5fd99tvv616OAd269atbP3rr7/O1p999tkqhzNzOEIAEAgEAIFAABAIBACBQAAQCAQAgUAAEOhDuEddunRpaG2cfQZl/vnnn2z94sWL2frZs2ez9bJ7Ncw6jhAABAIBQCAQAAQCAUAgEAAEAgFA4LLjPeqNN94YWvvll1+y+3788cdVD6cy33//fbb+9NNPZ+tffvnl0NoDDzxwpDHdSzhCABAIBACBQAAQCAQAgUAAEAgEAIFAABDoQ5hBZW8hXl5eztbX1tay9bJega2traG1n376KbtvmbLXvn379tAafQgcIQAoIBAABAIBQCAQAAQCAUAgEAAEAgFAoA9hBs3NzWXrm5ubIz1/WR/DI488MrR25syZkV4bo+EIAUAgEAAEAgFAIBAABAIBQDjwVQYzW5PUdfftAbUVSQ1JHUl1SZ1BjwMw2Q4UCGa2Kum/ktYH1OqSmu5+urDtspl13L1T2UgBHLvsKYOZ1c2spd5v/TtDHrYhqdW3rSWpOfrwAJykbCC4e8fdN9x9+B0tpDVJ1/u2tdN2AFNkpEVFM5vXgKMHd++men2U5wdwska9ylCT9gJgAAIBmCKjBsL8UXYys/Nm1jaz9s7OzohDAFCVsfQhuPuWuzfcvbGwsDCOIQAYoJJASGsJAKbcqIGw22dQK24sBAR9CMAUGel+CO7eNbOO9q8l1NTraiQQsM/Vq1eH1tx9pOcedf9ZV8Upw7Z6bctFK2k7gClymECoafBVhU3tb2neSNsBTJHsKUNaC7igXj/BvKSmmZ2W9J27X5HitGHTzN7S3pubmpwuANMnGwip4aj0N727X9f+9mUAU4b7IQAIBAKAwG3YUbkbN25k659++unQmpmN9NqLi4vZetkt6GcdRwgAAoEAIBAIAAKBACAQCAACgQAgEAgAAn0IqFzZR7rfunXr2F77lVdeydZzH0UPjhAAFBAIAAKBACAQCAACgQAgEAgAAoEAINCHgEO7cuVKtv7rr79m66Pc82B9vf9+vnd79913j/zc4AgBQAGBACAQCAACgQAgEAgAAoEAIBAIAAJ9CBOq2+1m65cuXcrWcx+LXtYH0Gq1svWyPoNRPpJ9fn7Q5wnvee2114783CjHEQKAQCAACAQCgEAgAAgEAoBAIAAIBAKAQB/CMblx40a2/sILL2Trf/75Z7b+xx9/ZOuj9CGUOc79y/oMnnzyyWy9bN4feuihobW5ubnsvrOAIwQAgUAAEAgEAIFAABAIBACBQAAQuOw4gp2dnaG1Tz75JLvvjz/+WPVw7gmfffZZtn7u3Lls/fnnn8/Wv/rqq6G15eXl7L6zgCMEAIFAABAIBACBQAAQCAQAgUAAEAgEAIE+hIyPPvooW9/a2hpa+/nnn6sezky4efNmtv7oo49m66PcAh4cIQAoIBAABAIBQCAQAAQCAUAgEAAEAgFAmOk+hG+++SZbf/31109oJNUb5Xr8c889l60vLi5m6x9++OGRX3tU9CGMhiMEAIFAABAIBACBQAAQCAQA4UBXGcxsTVJd0nL6u+XuV/oesyKpIamTHtNx9+1qhwvgOJUGQgqDzm4AmNm8pGtmVnP3rbStLqnp7qcL+102s467d45p7AAqdpAjhHrxaMDdu2bWlNSStHtDgI30fVFLUlPSehUDPQ4LCwvZ+sMPP5yt//XXX1UO58Q89dRT2fo777yTrT/22GPZ+vz8fLb+3nvvZevH6c033xxaK/ssjbL/L/eC7BpCOhr4d/q7aDvV6+n7NUnX+x7TTtsBTIlsILh7V731gPqwx6SwqEu6M2DfYmgAmHClVxnc/UF37//tvyKpm9YHaulx3SFPQSAAU+Kolx0vSPogfZ0/YRzAzM6bWdvM2rnPRwRwsg4dCGZ2XtIdd//PUV/U3bfcveHujVlYqAGmxaECIa0HbBQvLxZqhz5SADBZDvv256akZ/q27fYZ1CTFOkIhICa2D6HRaGTrZZehXnzxxaG1bnfYksrB3H///dn60tJStv7EE08MrV28eDG779zcXLZe5uWXX87Wcx/Jfty3r//hhx+G1n777bfsvrNwNHvgIwQza0l6tX/xMH3f0f61hJr2Fh4BTIEDBUJaN2gWw8DMVguXFLfVa1suWknbAUyJ0kBIrcu7X9fNbMXMViWtF377b2p/R+JG2g5gSmTXENI6wOUh5TgVSO3Mm2b2lvbe3NTkdAGYLtlASKcIdpAnSs1L/Q1MAKYI90MAEAgEAMHGfdvqRqPh7XZ7rGM4qqtXrw6tjXo9vewtxC+99NJIzz9OudvfnzlzJrvv+nr+3fSPP/54tp67hfzZs2ez+04zM7vm7vnGG3GEAKCAQAAQCAQAgUAAEAgEAIFAABAIBACBPgRgBtCHAODQCAQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAAEAgEAIFAABAIBACBQAAQCAQAwdx9vAMw25F0s7DplKTbYxrONGPejmZW5m3R3RfKHjT2QOhnZm13b4x7HNOGeTsa5u1unDIACAQCgDCJgbA17gFMKebtaJi3golbQwAwPpN4hABgTAgEAOG+cQ9gl5mtSGpI6kiqS+q4+/Z4RzV5zGxNUnfQ3DCHg6U5q0taTn+33P1K32OYO0ly97H/Ue8H8F3ftsuS6uMe2yT9kbQq6W9Jq8zhgedsTdJK4ft5Sb9LOs/c7f8zKacMG5JafdtakppjGMvEMbO6mbXU+497Z8jDmMPB6u5+ffcbd++qNyfFuWLukom4ymBmv0s67e6dwrZ5SX+7u41vZJMnzdWG9x3OMof7pX///yQ9k4Jgd3tdvaOEZXfvMHd7xn6EkCZ+32++3R9g+uEhgzkcLP376+nPQMzd3cYeCJJq0t4PYICZ+oEcEXM4hLs/WDxlSFbUW5jtiLm7yyQEwvy4B3APYA4P54KkD9LXzF3BJAQCcGLM7LykO+7+n3GPZRJNTCCkczmMgDnMS+sBG+5+ekCNudNkBMLuym6tuLHwA+oIZZjDg2lKeqZvG3NXMPZASIs5He0/l6tpb+EHGcxhudTH8Wr/4iFzd7exB0KyrV7baNFK2o6DYQ6HSOsGzb5ehNXCJUXmLpmUQNiUtN63bSNtx91qGrwyzhwOkN7HsPt13cxWzGxV0nrhtz9zl0xEp6IUby5Z1d6bS673d+PNqnQ+e0G9eVlTb4621eu/v1J4HHNYsNttOKTccfflwmOZO01QIAAYv0k5ZQAwAQgEAIFAABAIBACBQAAQCAQAgUAAEAgEAIFAABAIBADh/wm0H7wLvjwhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = np.random.choice(np.arange(n_train))\n",
    "\n",
    "image = x_train[example,:,:,0]\n",
    "label = y_train[example]\n",
    "\n",
    "plt.imshow(image, cmap = cm.binary)\n",
    "print(\"Digit: {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we encode the data labels as one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels):\n",
    "    \"\"\"\n",
    "    Encodes a list of labels ranging between (0-9) as one-hot vectors.\n",
    "    0 -> [1,0,0,0,0,0,0,0,0,0]\n",
    "    9 -> [0,0,0,0,0,0,0,0,0,1]\n",
    "    \"\"\"\n",
    "    one_hot_labels = []\n",
    "    for num in labels:\n",
    "        one_hot = [0.0]*10\n",
    "        one_hot[num] = 1.0\n",
    "        one_hot_labels.append(one_hot)\n",
    "    return np.array(one_hot_labels).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_oh = one_hot(y_train)\n",
    "y_test_oh = one_hot(y_test)\n",
    "y_train_oh.shape, y_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0],y_train_oh[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a small sample dataset for preliminary debugging/architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 28, 28, 1), (20,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample = x_train[0:20,:,:,:]\n",
    "y_sample = y_train[0:20]\n",
    "x_sample.shape, y_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_MNIST:\n",
    "    \"\"\"\n",
    "    Define a multilayer perceptron for the MNIST dataset\n",
    "    \n",
    "    Params\n",
    "    ------------\n",
    "    wd_factor : A double, the L2 regularisation factor for model parameters\n",
    "    learning_rate : A double, the learning rate for the Adam optimiser    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, wd_factor, learning_rate):\n",
    "        self.wd_factor = wd_factor # weight decay factor (L2 regulariser)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_pointer = 0 # for mini-batch housekeeping\n",
    "        self.test_pointer = 0\n",
    "        \n",
    "        self.input = tf.placeholder(dtype=tf.float32, shape=[None,784],name=\"input\")\n",
    "        self.ground_truth = tf.placeholder(dtype=tf.float32, shape=[None,10],name=\"ground_truth\")\n",
    "        print(self.input)\n",
    "        \n",
    "        # For batch norm and dropout, which work differently depending on whether you're \n",
    "        # training or testing\n",
    "        \n",
    "        self.is_training = tf.placeholder(tf.bool, name=\"is_training\")\n",
    "        \n",
    "        self._build_graph()\n",
    "        \n",
    "    def _build_graph(self):\n",
    "        \"\"\"\n",
    "        Create the convolutional neural network using the Adam optimiser and cross entropy loss\n",
    "        \"\"\"\n",
    "        weights = [] # for weight decay\n",
    "        \n",
    "        with tf.variable_scope(\"layers\"):\n",
    "            h = tf.layers.conv2d(self.input, 32, (3,3), strides=(1,1), padding=\"same\",\n",
    "                                 data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(),name='conv1')\n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h) # activation                        \n",
    "            \n",
    "            h = tf.layers.conv2d(h, 64, (3,3), strides=(1,1), padding=\"same\",\n",
    "                                 data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(),name='conv2')            \n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h) # activation            \n",
    "            h = tf.layers.max_pooling2d(h, (3,3), (3,3), padding='valid') # Downsample           \n",
    "            \n",
    "            h = tf.layers.conv2d(h, 64, (3,3), strides=(1,1), padding=\"same\",\n",
    "                                 data_format=\"channels_last\", activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(),name='conv3')\n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h) # activation            \n",
    "            h = tf.layers.max_pooling2d(h, (3,3), (3,3), padding='valid') # Downsample\n",
    "            \n",
    "            \n",
    "            # Fully connected layers\n",
    "            h = tf.layers.dense(h, 32, kernel_initializer=tf.glorot_uniform_initializer(),\n",
    "                               activation=tf.relu, name='dense1')            \n",
    "            h = tf.layers.dropout(h, rate=0.25, training=self.is_training, name=\"dropout1\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            self.logits = tf.layers.dense(h, 10, kernel_initializer=tf.glorot_uniform_initializer(),\n",
    "                               activation=tf.identity, name='dense2') # linear output for the loss function\n",
    "            print(self.logits)\n",
    "            self.prediction = tf.nn.softmax(self.logits, name=\"softmax_prediction\")\n",
    "        \n",
    "        with tf.name_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits,\n",
    "                                                                                 labels=self.ground_truth))\n",
    "            self.loss += self.weight_decay() # penalise weights with L2 norm\n",
    "        \n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "        \n",
    "    def weight_decay(self):\n",
    "        \"\"\"\n",
    "        Append the L2 penalty onto the loss function\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        for v in tf.global_variables():\n",
    "            if 'Adam' in v.name:\n",
    "                continue # do not punish optimizer variables\n",
    "            elif 'kernel' in v.name:\n",
    "                loss += self.wd_factor * tf.nn.l2_loss(v)\n",
    "        print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def train_minibatch(self, samples, labels, batch_size):\n",
    "        \"\"\"\n",
    "        Take a mini-batch from the training dataset\n",
    "        \"\"\"\n",
    "        if self.train_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.train_pointer: self.train_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.train_pointer: self.train_pointer + batch_size]\n",
    "            self.train_pointer += batch_size\n",
    "        else:\n",
    "            samples_minibatch = samples[self.train_pointer:]\n",
    "            labels_minibatch = labels[self.train_pointer:]\n",
    "            self.train_pointer += 0 # reset\n",
    "        return samples_minibatch, labels_minibatch\n",
    "    \n",
    "    def train(self, train_samples, train_labels, train_batch_size, iteration_steps, import_from_previous=False):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \n",
    "        Params\n",
    "        ----------\n",
    "        \n",
    "        train_samples: A numpy matrix containing the training data\n",
    "        train_labels: A numpy vector containing the labels corresponding to train_samples\n",
    "        train_batch_size: An int. The number of data points per mini-batch\n",
    "        iteration_steps: An int. The number of mini-batch training steps\n",
    "        import_from_previous: A bool. Load a previous model and train\n",
    "        \n",
    "        Returns\n",
    "        -----------\n",
    "        \n",
    "        losses: A numpy array, where the first column is the mini-batch index, and the \n",
    "                second column is the loss function\n",
    "        \"\"\"\n",
    "        print('Start training....')\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            if import_from_previous:\n",
    "                saver = tf.train.import_meta_graph(\"./model.meta\") # import the model\n",
    "                saver.restore(sess, './model') # populate with weights  \n",
    "            else:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                saver = tf.train.Saver() # for saving models\n",
    "            \n",
    "            for i in range(iteration_steps):\n",
    "                samples, labels = self.train_minibatch(train_samples, train_labels, train_batch_size)\n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels}\n",
    "                _, loss = sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "                if i % 50 == 0:\n",
    "                    print(\"Minibatch loss at step {}: {}\".format(i, loss))\n",
    "                    losses.append([i, loss])\n",
    "            saver.save(sess, './model') # save the model, generating 4 files\n",
    "        return np.array(losses)\n",
    "    \n",
    "    def test_minibatch(self, samples, labels, batch_size):\n",
    "        \"\"\"\n",
    "        Take a mini-batch from the test dataset\n",
    "        \"\"\"\n",
    "        if self.test_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.test_pointer: self.test_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.test_pointer: self.test_pointer + batch_size]\n",
    "            self.test_pointer += batch_size\n",
    "            end_of_epoch = False\n",
    "        else:\n",
    "            samples_minibatch = samples[self.test_pointer:]\n",
    "            labels_minibatch = labels[self.test_pointer:]\n",
    "            self.test_pointer += 0 # reset\n",
    "            end_of_epoch = True\n",
    "        return samples_minibatch, labels_minibatch, end_of_epoch\n",
    "    \n",
    "    def test(self, test_samples, test_labels, test_batch_size):\n",
    "        \"\"\"\n",
    "        Load a model, feed it test data, and determine the loss\n",
    "        \n",
    "        Params:\n",
    "        ---------------\n",
    "        test_samples: A numpy array, containing the test data\n",
    "        test_labels: A numpy vector, containing the test labels\n",
    "        test_batch_size: An int, the number of data points per mini-batch\n",
    "        \"\"\"\n",
    "        end_of_epoch = False\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver = tf.train.import_meta_graph(\"./model.meta\") # import the model\n",
    "            saver.restore(sess, './model') # populate with weights            \n",
    "            while not end_of_epoch: # run graph\n",
    "                samples, labels, end_of_epoch = self.test_minibatch(test_samples, \n",
    "                                                                    test_labels, test_batch_size)\n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels}                \n",
    "                losses.append(sess.run(self.loss, feed_dict=feed_dict))\n",
    "            print(\"Average test loss: {}\".format(np.mean(losses)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"layers/1/Tanh:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"layers/2/Tanh:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"layers/3/Tanh:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"layers/4/Tanh:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"loss/add_3:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "WD_FACTOR = 0.0001\n",
    "LEARNING_RATE = 0.001\n",
    "model = MLP_MNIST(WD_FACTOR, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layers/1/kernel:0' shape=(784, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/1/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/2/kernel:0' shape=(512, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/2/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/3/kernel:0' shape=(256, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/3/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/4/kernel:0' shape=(64, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/4/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'layers/1/kernel/Adam:0' shape=(784, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/1/kernel/Adam_1:0' shape=(784, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/1/bias/Adam:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/1/bias/Adam_1:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/2/kernel/Adam:0' shape=(512, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/2/kernel/Adam_1:0' shape=(512, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/2/bias/Adam:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/2/bias/Adam_1:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/3/kernel/Adam:0' shape=(256, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/3/kernel/Adam_1:0' shape=(256, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/3/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/3/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/4/kernel/Adam:0' shape=(64, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/4/kernel/Adam_1:0' shape=(64, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/4/bias/Adam:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/4/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_params():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():         \n",
    "        shape = variable.get_shape()        \n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value        \n",
    "        total_parameters += variable_parameters\n",
    "    print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550346\n"
     ]
    }
   ],
   "source": [
    "count_trainable_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 128\n",
    "ITERATIONS = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a learning schedule whereby we gradually reduce the learning rate with iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_schedule = [[2000,0.1],[2000,0.01],[2000,0.001],[4000,0.0001]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training....\n",
      "Minibatch loss at step 0: 2.4923176765441895\n",
      "Minibatch loss at step 50: 1.1161633729934692\n",
      "Minibatch loss at step 100: 1.0399525165557861\n",
      "Minibatch loss at step 150: 1.018926739692688\n",
      "Minibatch loss at step 200: 0.9745585322380066\n",
      "Minibatch loss at step 250: 1.0181118249893188\n",
      "Minibatch loss at step 300: 0.9630082845687866\n",
      "Minibatch loss at step 350: 1.0267927646636963\n",
      "Minibatch loss at step 400: 0.9970570206642151\n",
      "Minibatch loss at step 450: 0.9601716995239258\n",
      "Minibatch loss at step 500: 0.8683041334152222\n",
      "Minibatch loss at step 550: 0.8655282855033875\n",
      "Minibatch loss at step 600: 0.8637357354164124\n",
      "Minibatch loss at step 650: 0.8621584177017212\n",
      "Minibatch loss at step 700: 0.860696017742157\n",
      "Minibatch loss at step 750: 0.8593116998672485\n",
      "Minibatch loss at step 800: 0.8579868674278259\n",
      "Minibatch loss at step 850: 0.8567106127738953\n",
      "Minibatch loss at step 900: 0.8554755449295044\n",
      "Minibatch loss at step 950: 0.8542769551277161\n",
      "Minibatch loss at step 1000: 0.8531115651130676\n",
      "Minibatch loss at step 1050: 0.8519772291183472\n",
      "Minibatch loss at step 1100: 0.8508725166320801\n",
      "Minibatch loss at step 1150: 0.8497959971427917\n",
      "Minibatch loss at step 1200: 0.8487468361854553\n",
      "Minibatch loss at step 1250: 0.8477246761322021\n",
      "Minibatch loss at step 1300: 0.8467288017272949\n",
      "Minibatch loss at step 1350: 0.8457592725753784\n",
      "Minibatch loss at step 1400: 0.8448154926300049\n",
      "Minibatch loss at step 1450: 0.8438974022865295\n",
      "Minibatch loss at step 1500: 0.8430047631263733\n",
      "Minibatch loss at step 1550: 0.8421376347541809\n",
      "Minibatch loss at step 1600: 0.8412957787513733\n",
      "Minibatch loss at step 1650: 0.8404790759086609\n",
      "Minibatch loss at step 1700: 0.8396872878074646\n",
      "Minibatch loss at step 1750: 0.8389202356338501\n",
      "Minibatch loss at step 1800: 0.8381778597831726\n",
      "Minibatch loss at step 1850: 0.837459921836853\n",
      "Minibatch loss at step 1900: 0.8367659449577332\n",
      "Minibatch loss at step 1950: 0.8360958695411682\n",
      "Start training....\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Minibatch loss at step 0: 0.8354493379592896\n",
      "Minibatch loss at step 50: 0.8348260521888733\n",
      "Minibatch loss at step 100: 0.8342254161834717\n",
      "Minibatch loss at step 150: 0.8336474299430847\n",
      "Minibatch loss at step 200: 0.8330913782119751\n",
      "Minibatch loss at step 250: 0.8325569033622742\n",
      "Minibatch loss at step 300: 0.832043468952179\n",
      "Minibatch loss at step 350: 0.8315507173538208\n",
      "Minibatch loss at step 400: 0.831078052520752\n",
      "Minibatch loss at step 450: 0.830625057220459\n",
      "Minibatch loss at step 500: 0.8301911354064941\n",
      "Minibatch loss at step 550: 0.8297759294509888\n",
      "Minibatch loss at step 600: 0.8293786644935608\n",
      "Minibatch loss at step 650: 0.8289988040924072\n",
      "Minibatch loss at step 700: 0.8286350965499878\n",
      "Minibatch loss at step 750: 0.8282778859138489\n",
      "Minibatch loss at step 800: 0.8079203963279724\n",
      "Minibatch loss at step 850: 0.8072212934494019\n",
      "Minibatch loss at step 900: 0.8068068623542786\n",
      "Minibatch loss at step 950: 0.8064666390419006\n",
      "Minibatch loss at step 1000: 0.8061650991439819\n",
      "Minibatch loss at step 1050: 0.805888831615448\n",
      "Minibatch loss at step 1100: 0.8056315779685974\n",
      "Minibatch loss at step 1150: 0.805390477180481\n",
      "Minibatch loss at step 1200: 0.8051636815071106\n",
      "Minibatch loss at step 1250: 0.8049499988555908\n",
      "Minibatch loss at step 1300: 0.8047483563423157\n",
      "Minibatch loss at step 1350: 0.8045580983161926\n",
      "Minibatch loss at step 1400: 0.8043786883354187\n",
      "Minibatch loss at step 1450: 0.804209291934967\n",
      "Minibatch loss at step 1500: 0.8040493726730347\n",
      "Minibatch loss at step 1550: 0.8038986921310425\n",
      "Minibatch loss at step 1600: 0.8037564158439636\n",
      "Minibatch loss at step 1650: 0.8036224246025085\n",
      "Minibatch loss at step 1700: 0.8034960031509399\n",
      "Minibatch loss at step 1750: 0.8033768534660339\n",
      "Minibatch loss at step 1800: 0.8032646179199219\n",
      "Minibatch loss at step 1850: 0.8031588196754456\n",
      "Minibatch loss at step 1900: 0.8030592203140259\n",
      "Minibatch loss at step 1950: 0.8029654622077942\n",
      "Start training....\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Minibatch loss at step 0: 0.8028771877288818\n",
      "Minibatch loss at step 50: 0.8027940392494202\n",
      "Minibatch loss at step 100: 0.8027157783508301\n",
      "Minibatch loss at step 150: 0.8026421666145325\n",
      "Minibatch loss at step 200: 0.8025728464126587\n",
      "Minibatch loss at step 250: 0.8025076389312744\n",
      "Minibatch loss at step 300: 0.8024462461471558\n",
      "Minibatch loss at step 350: 0.8023883700370789\n",
      "Minibatch loss at step 400: 0.8023340106010437\n",
      "Minibatch loss at step 450: 0.8022828102111816\n",
      "Minibatch loss at step 500: 0.8022345900535583\n",
      "Minibatch loss at step 550: 0.8021891713142395\n",
      "Minibatch loss at step 600: 0.8021464943885803\n",
      "Minibatch loss at step 650: 0.8021061420440674\n",
      "Minibatch loss at step 700: 0.8020681142807007\n",
      "Minibatch loss at step 750: 0.8020323514938354\n",
      "Minibatch loss at step 800: 0.8019986152648926\n",
      "Minibatch loss at step 850: 0.801966667175293\n",
      "Minibatch loss at step 900: 0.8019366264343262\n",
      "Minibatch loss at step 950: 0.8019082546234131\n",
      "Minibatch loss at step 1000: 0.8018813133239746\n",
      "Minibatch loss at step 1050: 0.8018558621406555\n",
      "Minibatch loss at step 1100: 0.8018319010734558\n",
      "Minibatch loss at step 1150: 0.8018090128898621\n",
      "Minibatch loss at step 1200: 0.8017874360084534\n",
      "Minibatch loss at step 1250: 0.8017669320106506\n",
      "Minibatch loss at step 1300: 0.8017474412918091\n",
      "Minibatch loss at step 1350: 0.8017289042472839\n",
      "Minibatch loss at step 1400: 0.8017112016677856\n",
      "Minibatch loss at step 1450: 0.801694393157959\n",
      "Minibatch loss at step 1500: 0.8016783595085144\n",
      "Minibatch loss at step 1550: 0.8016629815101624\n",
      "Minibatch loss at step 1600: 0.8016483187675476\n",
      "Minibatch loss at step 1650: 0.8016341924667358\n",
      "Minibatch loss at step 1700: 0.8016207218170166\n",
      "Minibatch loss at step 1750: 0.8016077876091003\n",
      "Minibatch loss at step 1800: 0.8015952706336975\n",
      "Minibatch loss at step 1850: 0.8015832304954529\n",
      "Minibatch loss at step 1900: 0.8015716075897217\n",
      "Minibatch loss at step 1950: 0.8015603423118591\n",
      "Start training....\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Minibatch loss at step 0: 0.8015494346618652\n",
      "Minibatch loss at step 50: 0.8015388250350952\n",
      "Minibatch loss at step 100: 0.8015286326408386\n",
      "Minibatch loss at step 150: 0.8015186786651611\n",
      "Minibatch loss at step 200: 0.8015088438987732\n",
      "Minibatch loss at step 250: 0.8014994859695435\n",
      "Minibatch loss at step 300: 0.801490068435669\n",
      "Minibatch loss at step 350: 0.8014810681343079\n",
      "Minibatch loss at step 400: 0.8014721870422363\n",
      "Minibatch loss at step 450: 0.8014635443687439\n",
      "Minibatch loss at step 500: 0.8014548420906067\n",
      "Minibatch loss at step 550: 0.8014465570449829\n",
      "Minibatch loss at step 600: 0.8014383316040039\n",
      "Minibatch loss at step 650: 0.8014302253723145\n",
      "Minibatch loss at step 700: 0.801422119140625\n",
      "Minibatch loss at step 750: 0.8014143109321594\n",
      "Minibatch loss at step 800: 0.8014065623283386\n",
      "Minibatch loss at step 850: 0.8013989329338074\n",
      "Minibatch loss at step 900: 0.8013913631439209\n",
      "Minibatch loss at step 950: 0.801383912563324\n",
      "Minibatch loss at step 1000: 0.8013765811920166\n",
      "Minibatch loss at step 1050: 0.8013692498207092\n",
      "Minibatch loss at step 1100: 0.8013620376586914\n",
      "Minibatch loss at step 1150: 0.8013548851013184\n",
      "Minibatch loss at step 1200: 0.8013479113578796\n",
      "Minibatch loss at step 1250: 0.8013409972190857\n",
      "Minibatch loss at step 1300: 0.8013341426849365\n",
      "Minibatch loss at step 1350: 0.8013273477554321\n",
      "Minibatch loss at step 1400: 0.8013206720352173\n",
      "Minibatch loss at step 1450: 0.8013139963150024\n",
      "Minibatch loss at step 1500: 0.8013074398040771\n",
      "Minibatch loss at step 1550: 0.8013009428977966\n",
      "Minibatch loss at step 1600: 0.8012945055961609\n",
      "Minibatch loss at step 1650: 0.8012881278991699\n",
      "Minibatch loss at step 1700: 0.8012818098068237\n",
      "Minibatch loss at step 1750: 0.8012756705284119\n",
      "Minibatch loss at step 1800: 0.8012694716453552\n",
      "Minibatch loss at step 1850: 0.8012633919715881\n",
      "Minibatch loss at step 1900: 0.801257312297821\n",
      "Minibatch loss at step 1950: 0.8012514710426331\n",
      "Minibatch loss at step 2000: 0.8012455105781555\n",
      "Minibatch loss at step 2050: 0.8012397885322571\n",
      "Minibatch loss at step 2100: 0.8012341260910034\n",
      "Minibatch loss at step 2150: 0.8012283444404602\n",
      "Minibatch loss at step 2200: 0.8012227416038513\n",
      "Minibatch loss at step 2250: 0.8012171387672424\n",
      "Minibatch loss at step 2300: 0.8012115955352783\n",
      "Minibatch loss at step 2350: 0.8012062311172485\n",
      "Minibatch loss at step 2400: 0.8012007474899292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 2450: 0.801195502281189\n",
      "Minibatch loss at step 2500: 0.801190197467804\n",
      "Minibatch loss at step 2550: 0.801184892654419\n",
      "Minibatch loss at step 2600: 0.8011797666549683\n",
      "Minibatch loss at step 2650: 0.801174521446228\n",
      "Minibatch loss at step 2700: 0.8011693358421326\n",
      "Minibatch loss at step 2750: 0.8011642694473267\n",
      "Minibatch loss at step 2800: 0.8011592030525208\n",
      "Minibatch loss at step 2850: 0.8011540770530701\n",
      "Minibatch loss at step 2900: 0.8011489510536194\n",
      "Minibatch loss at step 2950: 0.801144003868103\n",
      "Minibatch loss at step 3000: 0.8011389374732971\n",
      "Minibatch loss at step 3050: 0.8011337518692017\n",
      "Minibatch loss at step 3100: 0.8011286854743958\n",
      "Minibatch loss at step 3150: 0.8011236190795898\n",
      "Minibatch loss at step 3200: 0.8011184930801392\n",
      "Minibatch loss at step 3250: 0.8011134266853333\n",
      "Minibatch loss at step 3300: 0.8011084198951721\n",
      "Minibatch loss at step 3350: 0.801103413105011\n",
      "Minibatch loss at step 3400: 0.8010984063148499\n",
      "Minibatch loss at step 3450: 0.8010934591293335\n",
      "Minibatch loss at step 3500: 0.8010885119438171\n",
      "Minibatch loss at step 3550: 0.8010836839675903\n",
      "Minibatch loss at step 3600: 0.8010788559913635\n",
      "Minibatch loss at step 3650: 0.8010740280151367\n",
      "Minibatch loss at step 3700: 0.8010693788528442\n",
      "Minibatch loss at step 3750: 0.8010646104812622\n",
      "Minibatch loss at step 3800: 0.8010600209236145\n",
      "Minibatch loss at step 3850: 0.8010554909706116\n",
      "Minibatch loss at step 3900: 0.8010509610176086\n",
      "Minibatch loss at step 3950: 0.8010464310646057\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i, vals in enumerate(learning_schedule):\n",
    "    ITERATIONS = vals[0]\n",
    "    LR = vals[1]\n",
    "    if i == 0:\n",
    "        model.learning_rate = LR\n",
    "        losses = model.train(x_train_flat, y_train_oh, TRAIN_BATCH_SIZE, ITERATIONS)\n",
    "    else:\n",
    "\n",
    "        losses_new = model.train(x_train_flat, y_train_oh, TRAIN_BATCH_SIZE, ITERATIONS, import_from_previous = True)\n",
    "        losses_new[:,0] += losses[-1,0] + TRAIN_BATCH_SIZE\n",
    "        losses = np.vstack((losses,losses_new))\n",
    "end_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 113.69104361534119s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training time: {}s\".format(end_time - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = losses[:,0]\n",
    "train_loss = losses[:,1]\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "utls.remove_tex_axis(ax, ytick_fmt=\"%.1f\")\n",
    "ax.plot(iterations, train_loss,'-k')\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Loss')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test network predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Average test loss: 1.7568947076797485\n"
     ]
    }
   ],
   "source": [
    "model.test(x_test_flat,y_test_oh, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Test sample digit: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "example = np.random.choice(n_test)\n",
    "\n",
    "sample = x_test_flat[example]\n",
    "label = y_test_oh[example]\n",
    "feed_dict = {model.input: np.expand_dims(sample, axis=0), \n",
    "             model.ground_truth: np.expand_dims(label,axis=0)}\n",
    "\n",
    "digit = np.where(label==1.0)[0][0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "    saver.restore(sess, './model')\n",
    "    prediction = sess.run(model.prediction, feed_dict = feed_dict)[0]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(2*5,5))\n",
    "axs = axs.ravel()\n",
    "\n",
    "ax = axs[0]\n",
    "utls.remove_tex_axis(ax)\n",
    "ax.imshow(x_test[example],cmap=cm.binary)\n",
    "ax.set_title('Test example')\n",
    "\n",
    "classes = np.arange(10)\n",
    "width = 0.5\n",
    "\n",
    "ax = axs[1]\n",
    "\n",
    "ax.bar(classes, prediction, width, color='Black')\n",
    "utls.remove_tex_axis(ax,ytick_fmt=\"%.2f\")\n",
    "ax.set_xticks(classes)\n",
    "ax.set_xticklabels([str(x) for x in np.arange(10)])\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Digit class')\n",
    "ax.set_title('Network categorical distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "print('Test sample digit: {}'.format(digit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
